{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WZL Automobile Data processing\n",
    "\n",
    "Objective: identify if a coil is somehow different from existing observations.()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xiaoli yang\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy import stats\n",
    "import tensorflow as tf\n",
    "#import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import io\n",
    "import os\n",
    "\n",
    "path=r\"D:/ubuntu/WZL-2018/Automobil_training_data\"\n",
    "filename = path + '/Datenbasis_Gefiltert.csv'\n",
    "df = pd.read_csv(filename, usecols=['Position', 'CoilNumber','ProgramNumber630','Banddicke1','Banddicke2','Banddicke3','Banddicke','Impoc'])\n",
    "#df = df.dropna(axis=0,subset=['Banddicke2','Impoc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "After loading the Columns we wanted, we'd better combine the two table(with producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length zrd 19\n",
      "length df 17\n",
      "(1048575, 17)\n",
      "(1048575, 20)\n"
     ]
    }
   ],
   "source": [
    "zrd=pd.read_csv(os.path.join(path,'Zuordnung.csv'),header=0,sep=',')\n",
    "zrd.rename(index=str,columns ={'programm_coil':'ProgramNumber630',\n",
    "'material gemaess SAP':'Material',\n",
    "'Hersteller/Schluessel':'Hersteller'},inplace = True)\n",
    "print('length zrd {:d}'.format(len( zrd.loc[:,'ProgramNumber630'].unique() ) ) )\n",
    "print('length df {:d}' .format(len( df.loc[:,'ProgramNumber630'].unique() ) ) )\n",
    "print(df.shape)\n",
    "\n",
    "df=pd.merge(df, zrd, how='left', on=['ProgramNumber630'])\n",
    "print(df.shape)\n",
    "\n",
    "df.to_csv(os.path.join(path,'Datenbasis_Gefiltert_zusammengefuehrt.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "* denoising\n",
    "\n",
    "1. dropna\n",
    "2. delete duplicate\n",
    "3. choose only one Hersteller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539394, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as for the precision round(3)\n",
    "df.dropna(axis=0, how='any',inplace=True)\n",
    "df.round(3)\n",
    "df.drop_duplicates(subset=['Position'],inplace=True)\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1 \n",
    "\n",
    "let's say we choose the `Hersteller CV` and the `Branddicke=0.7`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = df.loc[(df['Hersteller'] == 'CV') & (df['Banddicke'] == 0.7)]\n",
    "#df_cv = df_cv.drop(columns = ['CoilNumber','Material','Hersteller'])\n",
    "#df_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "before we start our training, we can take a deeper look inside of our data to say what's good or not.\n",
    "\n",
    "1. group the data by the coilnumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a67c4bc32cd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcoilNr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CoilNumber'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'last'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoilNumber\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;31m# it will return a series.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CoilNumber'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m    \u001b[1;31m#print(s[1]['Banddicke2'].values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_cv' is not defined"
     ]
    }
   ],
   "source": [
    "coilNr = df_cv.drop_duplicates(subset=['CoilNumber'], keep='last', inplace=False).CoilNumber.values # it will return a series.\n",
    "i=1\n",
    "for s in df_cv.groupby('CoilNumber'):\n",
    "   #print(s[1]['Banddicke2'].values)\n",
    "    if(s[1].size<8000):\n",
    "        continue\n",
    "    xx = pd.DataFrame({'Position':s[1]['Position'].values,'Banddicke2':s[1]['Banddicke2'].values})\n",
    "    #print(s[1].size)\n",
    "    xx.plot(x='Position',y='Banddicke2',title=s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.1 Setup the Autoencoder based on Tensorflow\n",
    "\n",
    "here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform the data into matrix as a unit\n",
    "# s in df_cv.groupby('CoilNumber'):\n",
    "import random\n",
    "\n",
    "df_matrix = pd.DataFrame([])\n",
    "\n",
    "# how long the step size should be\n",
    "Step = 500\n",
    "\n",
    "for s in df_cv.groupby('CoilNumber'):\n",
    "    \n",
    "    #matrx = pd.DataFrame([s[1].Position.values, s[1].Banddicke1.values, s[1].Banddicke2.values, s[1].Banddicke3.values])\n",
    "    #matrx = np.split(',')\n",
    "    #matrx = np.transpose(matrx)\n",
    "    #comp = Step - (matrx.shape[0] % Step)\n",
    "    #new = matrx[-1]\n",
    "    #new = np.tile(new, comp)\n",
    "    #length = matrx.shape[0]\n",
    "    #matrx = np.append(matrx,new).shape(length+comp,4)\n",
    "    comp = Step - s[1].shape[0] % Step\n",
    "    matrx = s[1].filter(items=['Position', 'Banddicke1','Banddicke2','Banddicke3'])\n",
    "    ran = matrx[-1:]['Position'].values[0]\n",
    "    for i in range(int(comp)):\n",
    "        ranPos = round(random.uniform(1, ran), 3)\n",
    "        d2 = pd.DataFrame([[ranPos,0.7,0.7,0.7]], columns= ['Position', 'Banddicke1', 'Banddicke2', 'Banddicke3'])\n",
    "        matrx = matrx.append(d2)\n",
    "    df_matrix = df_matrix.append(matrx)\n",
    "    #print(s[1].filter(items=['Position', 'Banddicke1','Banddicke2','Banddick3']))\n",
    "    \n",
    "df_matrix.drop('Position',axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3x3 network(3 layers encoders and 3 layers decoders).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "X_train, X_test = train_test_split(df_matrix, test_size=0.25, random_state=RANDOM_SEED)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(int(len(X_train)/500), 3*500)\n",
    "X_test = X_test.reshape(int(len(X_test)/500), 3*500)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 250\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 5), activation=\"relu\")(encoder)\n",
    "encoder = Dense(int(encoding_dim / 25), activation=\"relu\")(encoder)\n",
    "\n",
    "decoder = Dense(int(encoding_dim / 5), activation='tanh')(encoder)\n",
    "decoder = Dense(int(encoding_dim / 25), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "train the module for 100 Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117 samples, validate on 39 samples\n",
      "Epoch 1/500\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5367 - acc: 0.0000e+00 - val_loss: 0.3932 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.4456 - acc: 0.0000e+00 - val_loss: 0.4152 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4312 - acc: 0.0000e+00 - val_loss: 0.3898 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3895 - acc: 0.0000e+00 - val_loss: 0.3500 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3625 - acc: 0.0000e+00 - val_loss: 0.3346 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3531 - acc: 0.0000e+00 - val_loss: 0.3212 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3385 - acc: 0.0000e+00 - val_loss: 0.3206 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3323 - acc: 0.0000e+00 - val_loss: 0.3151 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3266 - acc: 0.0000e+00 - val_loss: 0.3008 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "117/117 [==============================] - 0s 920us/step - loss: 0.3212 - acc: 0.0085 - val_loss: 0.3060 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3152 - acc: 0.0000e+00 - val_loss: 0.2966 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "117/117 [==============================] - 0s 806us/step - loss: 0.3096 - acc: 0.0000e+00 - val_loss: 0.2982 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3108 - acc: 0.0000e+00 - val_loss: 0.3009 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.3200 - acc: 0.0000e+0 - 0s 2ms/step - loss: 0.3127 - acc: 0.0000e+00 - val_loss: 0.2959 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3084 - acc: 0.0000e+00 - val_loss: 0.2956 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3100 - acc: 0.0000e+00 - val_loss: 0.2945 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "117/117 [==============================] - 0s 904us/step - loss: 0.3088 - acc: 0.0000e+00 - val_loss: 0.2990 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3079 - acc: 0.0000e+00 - val_loss: 0.2987 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3087 - acc: 0.0000e+00 - val_loss: 0.2958 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3061 - acc: 0.0000e+00 - val_loss: 0.3013 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3144 - acc: 0.0000e+00 - val_loss: 0.2993 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3136 - acc: 0.0000e+00 - val_loss: 0.3008 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3101 - acc: 0.0000e+00 - val_loss: 0.2916 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3074 - acc: 0.0000e+00 - val_loss: 0.2876 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "117/117 [==============================] - 0s 762us/step - loss: 0.3009 - acc: 0.0000e+00 - val_loss: 0.2883 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3014 - acc: 0.0000e+00 - val_loss: 0.2940 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "117/117 [==============================] - 0s 985us/step - loss: 0.3020 - acc: 0.0000e+00 - val_loss: 0.2925 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3013 - acc: 0.0000e+00 - val_loss: 0.2937 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "117/117 [==============================] - 0s 774us/step - loss: 0.3071 - acc: 0.0000e+00 - val_loss: 0.2899 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3070 - acc: 0.0000e+00 - val_loss: 0.2946 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3043 - acc: 0.0000e+00 - val_loss: 0.2898 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3057 - acc: 0.0000e+00 - val_loss: 0.2937 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3064 - acc: 0.0000e+00 - val_loss: 0.3017 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3101 - acc: 0.0000e+00 - val_loss: 0.2995 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3086 - acc: 0.0000e+00 - val_loss: 0.2905 - val_acc: 0.0256\n",
      "Epoch 36/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3040 - acc: 0.0000e+00 - val_loss: 0.2868 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3043 - acc: 0.0000e+00 - val_loss: 0.2950 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3064 - acc: 0.0000e+00 - val_loss: 0.2918 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3061 - acc: 0.0000e+00 - val_loss: 0.2851 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.3014 - acc: 0.0000e+00 - val_loss: 0.2841 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2973 - acc: 0.0000e+00 - val_loss: 0.2927 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3040 - acc: 0.0085 - val_loss: 0.2969 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3056 - acc: 0.0000e+00 - val_loss: 0.2898 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3012 - acc: 0.0085 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3002 - acc: 0.0000e+00 - val_loss: 0.2899 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3023 - acc: 0.0000e+00 - val_loss: 0.2937 - val_acc: 0.0256\n",
      "Epoch 47/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3056 - acc: 0.0000e+00 - val_loss: 0.3008 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3107 - acc: 0.0000e+00 - val_loss: 0.2954 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3070 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3051 - acc: 0.0000e+00 - val_loss: 0.2921 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3070 - acc: 0.0000e+00 - val_loss: 0.2882 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3038 - acc: 0.0000e+00 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3054 - acc: 0.0000e+00 - val_loss: 0.2960 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3060 - acc: 0.0000e+00 - val_loss: 0.2933 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "117/117 [==============================] - 0s 996us/step - loss: 0.3100 - acc: 0.0000e+00 - val_loss: 0.2929 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3080 - acc: 0.0000e+00 - val_loss: 0.2979 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3072 - acc: 0.0000e+00 - val_loss: 0.2995 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3106 - acc: 0.0000e+00 - val_loss: 0.2861 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3015 - acc: 0.0000e+00 - val_loss: 0.2874 - val_acc: 0.0256\n",
      "Epoch 60/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.0085 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3008 - acc: 0.0000e+00 - val_loss: 0.2943 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3022 - acc: 0.0000e+00 - val_loss: 0.2883 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.0000e+00 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3023 - acc: 0.0000e+00 - val_loss: 0.2965 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3069 - acc: 0.0000e+00 - val_loss: 0.2943 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3091 - acc: 0.0000e+00 - val_loss: 0.2929 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3037 - acc: 0.0085 - val_loss: 0.2864 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2981 - acc: 0.0000e+00 - val_loss: 0.2873 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3000 - acc: 0.0085 - val_loss: 0.2864 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2997 - acc: 0.0085 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3004 - acc: 0.0085 - val_loss: 0.2888 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2977 - acc: 0.0085 - val_loss: 0.2904 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3019 - acc: 0.0000e+00 - val_loss: 0.2845 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3003 - acc: 0.0171 - val_loss: 0.2862 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2955 - acc: 0.0000e+00 - val_loss: 0.2838 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2993 - acc: 0.0085 - val_loss: 0.2913 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "117/117 [==============================] - 0s 858us/step - loss: 0.3009 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "117/117 [==============================] - 0s 851us/step - loss: 0.3033 - acc: 0.0000e+00 - val_loss: 0.2912 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "117/117 [==============================] - 0s 702us/step - loss: 0.3033 - acc: 0.0000e+00 - val_loss: 0.2932 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.0000e+00 - val_loss: 0.2846 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "117/117 [==============================] - 0s 758us/step - loss: 0.3032 - acc: 0.0000e+00 - val_loss: 0.2891 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "117/117 [==============================] - 0s 990us/step - loss: 0.3010 - acc: 0.0000e+00 - val_loss: 0.2904 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.0000e+00 - val_loss: 0.2875 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.0000e+00 - val_loss: 0.2854 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3011 - acc: 0.0000e+00 - val_loss: 0.2907 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3014 - acc: 0.0000e+00 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "117/117 [==============================] - 0s 567us/step - loss: 0.3038 - acc: 0.0000e+00 - val_loss: 0.2925 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "117/117 [==============================] - 0s 608us/step - loss: 0.3023 - acc: 0.0000e+00 - val_loss: 0.2917 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "117/117 [==============================] - 0s 815us/step - loss: 0.3006 - acc: 0.0171 - val_loss: 0.2879 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "117/117 [==============================] - 0s 776us/step - loss: 0.2978 - acc: 0.0000e+00 - val_loss: 0.2871 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2991 - acc: 0.0000e+00 - val_loss: 0.2812 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "117/117 [==============================] - 0s 931us/step - loss: 0.2946 - acc: 0.0085 - val_loss: 0.2882 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2972 - acc: 0.0000e+00 - val_loss: 0.2928 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3045 - acc: 0.0000e+00 - val_loss: 0.2908 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "117/117 [==============================] - 0s 768us/step - loss: 0.2994 - acc: 0.0000e+00 - val_loss: 0.2861 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "117/117 [==============================] - 0s 749us/step - loss: 0.3031 - acc: 0.0085 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "117/117 [==============================] - 0s 674us/step - loss: 0.3039 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "117/117 [==============================] - 0s 708us/step - loss: 0.3045 - acc: 0.0000e+00 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "117/117 [==============================] - 0s 772us/step - loss: 0.3044 - acc: 0.0000e+00 - val_loss: 0.2926 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "117/117 [==============================] - 0s 791us/step - loss: 0.3038 - acc: 0.0000e+00 - val_loss: 0.2909 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.3080 - acc: 0.0000e+0 - 0s 870us/step - loss: 0.3020 - acc: 0.0000e+00 - val_loss: 0.2860 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2987 - acc: 0.0000e+00 - val_loss: 0.2876 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2997 - acc: 0.0085 - val_loss: 0.2876 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3019 - acc: 0.0085 - val_loss: 0.2924 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "117/117 [==============================] - 0s 745us/step - loss: 0.3063 - acc: 0.0085 - val_loss: 0.2879 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "117/117 [==============================] - 0s 666us/step - loss: 0.3033 - acc: 0.0000e+00 - val_loss: 0.2931 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "117/117 [==============================] - 0s 639us/step - loss: 0.3037 - acc: 0.0000e+00 - val_loss: 0.2992 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "117/117 [==============================] - 0s 666us/step - loss: 0.3120 - acc: 0.0000e+00 - val_loss: 0.2981 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "117/117 [==============================] - 0s 720us/step - loss: 0.3073 - acc: 0.0000e+00 - val_loss: 0.2925 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "117/117 [==============================] - 0s 870us/step - loss: 0.3065 - acc: 0.0000e+00 - val_loss: 0.2873 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3012 - acc: 0.0000e+00 - val_loss: 0.2850 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "117/117 [==============================] - 0s 915us/step - loss: 0.2997 - acc: 0.0000e+00 - val_loss: 0.2845 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "117/117 [==============================] - 0s 937us/step - loss: 0.2965 - acc: 0.0000e+00 - val_loss: 0.2842 - val_acc: 0.0256\n",
      "Epoch 114/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2969 - acc: 0.0085 - val_loss: 0.2848 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 938us/step - loss: 0.2986 - acc: 0.0000e+00 - val_loss: 0.2860 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "117/117 [==============================] - 0s 867us/step - loss: 0.2978 - acc: 0.0000e+00 - val_loss: 0.2924 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "117/117 [==============================] - 0s 716us/step - loss: 0.2989 - acc: 0.0085 - val_loss: 0.2899 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "117/117 [==============================] - 0s 727us/step - loss: 0.2983 - acc: 0.0000e+00 - val_loss: 0.2854 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "117/117 [==============================] - 0s 806us/step - loss: 0.2980 - acc: 0.0000e+00 - val_loss: 0.2847 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "117/117 [==============================] - 0s 755us/step - loss: 0.2986 - acc: 0.0000e+00 - val_loss: 0.2858 - val_acc: 0.0000e+00\n",
      "Epoch 121/500\n",
      "117/117 [==============================] - 0s 769us/step - loss: 0.2990 - acc: 0.0085 - val_loss: 0.2891 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "117/117 [==============================] - 0s 737us/step - loss: 0.2981 - acc: 0.0000e+00 - val_loss: 0.2902 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "117/117 [==============================] - 0s 942us/step - loss: 0.2984 - acc: 0.0000e+00 - val_loss: 0.2870 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2992 - acc: 0.0085 - val_loss: 0.2916 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3030 - acc: 0.0000e+00 - val_loss: 0.2898 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "117/117 [==============================] - 0s 869us/step - loss: 0.3007 - acc: 0.0085 - val_loss: 0.2887 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "117/117 [==============================] - 0s 825us/step - loss: 0.2990 - acc: 0.0000e+00 - val_loss: 0.2896 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3045 - acc: 0.0000e+00 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "117/117 [==============================] - 0s 841us/step - loss: 0.3081 - acc: 0.0000e+00 - val_loss: 0.2994 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3052 - acc: 0.0000e+00 - val_loss: 0.2872 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "117/117 [==============================] - 0s 667us/step - loss: 0.3023 - acc: 0.0000e+00 - val_loss: 0.2930 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "117/117 [==============================] - 0s 982us/step - loss: 0.3062 - acc: 0.0000e+00 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3063 - acc: 0.0000e+00 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3006 - acc: 0.0000e+00 - val_loss: 0.2896 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3016 - acc: 0.0085 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2996 - acc: 0.0000e+00 - val_loss: 0.2935 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3022 - acc: 0.0000e+00 - val_loss: 0.2852 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3006 - acc: 0.0000e+00 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3024 - acc: 0.0000e+00 - val_loss: 0.2847 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "117/117 [==============================] - 0s 808us/step - loss: 0.3030 - acc: 0.0000e+00 - val_loss: 0.2931 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "117/117 [==============================] - 0s 697us/step - loss: 0.3026 - acc: 0.0000e+00 - val_loss: 0.2907 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "117/117 [==============================] - 0s 768us/step - loss: 0.3025 - acc: 0.0000e+00 - val_loss: 0.2901 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3029 - acc: 0.0000e+00 - val_loss: 0.2908 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3056 - acc: 0.0000e+00 - val_loss: 0.2955 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "117/117 [==============================] - 0s 948us/step - loss: 0.3091 - acc: 0.0000e+00 - val_loss: 0.2908 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "117/117 [==============================] - 0s 634us/step - loss: 0.3079 - acc: 0.0000e+00 - val_loss: 0.2942 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3069 - acc: 0.0000e+00 - val_loss: 0.2873 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "117/117 [==============================] - 0s 995us/step - loss: 0.3009 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "117/117 [==============================] - 0s 897us/step - loss: 0.3019 - acc: 0.0000e+00 - val_loss: 0.2911 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "117/117 [==============================] - 0s 686us/step - loss: 0.3016 - acc: 0.0000e+00 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "117/117 [==============================] - 0s 869us/step - loss: 0.3008 - acc: 0.0000e+00 - val_loss: 0.2918 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3015 - acc: 0.0000e+00 - val_loss: 0.2886 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3033 - acc: 0.0000e+00 - val_loss: 0.2850 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3004 - acc: 0.0000e+00 - val_loss: 0.2880 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3007 - acc: 0.0000e+00 - val_loss: 0.2952 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3029 - acc: 0.0000e+00 - val_loss: 0.2887 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3019 - acc: 0.0000e+00 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3023 - acc: 0.0000e+00 - val_loss: 0.2886 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3032 - acc: 0.0000e+00 - val_loss: 0.2918 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "117/117 [==============================] - 0s 769us/step - loss: 0.3019 - acc: 0.0000e+00 - val_loss: 0.2913 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "117/117 [==============================] - 0s 980us/step - loss: 0.3040 - acc: 0.0000e+00 - val_loss: 0.2949 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3043 - acc: 0.0085 - val_loss: 0.2864 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.0000e+00 - val_loss: 0.2898 - val_acc: 0.0000e+00\n",
      "Epoch 164/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3039 - acc: 0.0000e+00 - val_loss: 0.2892 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3001 - acc: 0.0000e+00 - val_loss: 0.2844 - val_acc: 0.0256\n",
      "Epoch 166/500\n",
      "117/117 [==============================] - 0s 933us/step - loss: 0.2961 - acc: 0.0000e+00 - val_loss: 0.2841 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2952 - acc: 0.0000e+00 - val_loss: 0.2841 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2965 - acc: 0.0000e+00 - val_loss: 0.2799 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2935 - acc: 0.0000e+00 - val_loss: 0.2831 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2935 - acc: 0.0000e+00 - val_loss: 0.2870 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2992 - acc: 0.0000e+00 - val_loss: 0.2822 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2984 - acc: 0.0000e+00 - val_loss: 0.2849 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2987 - acc: 0.0000e+00 - val_loss: 0.2895 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "117/117 [==============================] - 0s 951us/step - loss: 0.2975 - acc: 0.0085 - val_loss: 0.2831 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2988 - acc: 0.0000e+00 - val_loss: 0.2891 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2968 - acc: 0.0000e+00 - val_loss: 0.2917 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3027 - acc: 0.0000e+00 - val_loss: 0.2860 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.3011 - acc: 0.0000e+00 - val_loss: 0.2960 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3084 - acc: 0.0000e+00 - val_loss: 0.2925 - val_acc: 0.0256\n",
      "Epoch 180/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3087 - acc: 0.0000e+00 - val_loss: 0.2942 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3030 - acc: 0.0085 - val_loss: 0.2909 - val_acc: 0.0256\n",
      "Epoch 182/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3044 - acc: 0.0000e+00 - val_loss: 0.2913 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3030 - acc: 0.0000e+00 - val_loss: 0.2927 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3035 - acc: 0.0000e+00 - val_loss: 0.2939 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3060 - acc: 0.0000e+00 - val_loss: 0.2874 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2996 - acc: 0.0000e+00 - val_loss: 0.2839 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2968 - acc: 0.0000e+00 - val_loss: 0.2901 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2947 - acc: 0.0085 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3002 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3036 - acc: 0.0000e+00 - val_loss: 0.2878 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3026 - acc: 0.0000e+00 - val_loss: 0.2926 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3043 - acc: 0.0085 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3031 - acc: 0.0000e+00 - val_loss: 0.2888 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3001 - acc: 0.0085 - val_loss: 0.2936 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3050 - acc: 0.0000e+00 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3059 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3063 - acc: 0.0085 - val_loss: 0.2972 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3055 - acc: 0.0000e+00 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "117/117 [==============================] - 0s 899us/step - loss: 0.3033 - acc: 0.0085 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3031 - acc: 0.0000e+00 - val_loss: 0.2869 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2997 - acc: 0.0000e+00 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2982 - acc: 0.0000e+00 - val_loss: 0.2886 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3004 - acc: 0.0085 - val_loss: 0.2830 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2986 - acc: 0.0000e+00 - val_loss: 0.2887 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3024 - acc: 0.0000e+00 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3049 - acc: 0.0000e+00 - val_loss: 0.2904 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3038 - acc: 0.0000e+00 - val_loss: 0.2919 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3039 - acc: 0.0000e+00 - val_loss: 0.2859 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3003 - acc: 0.0000e+00 - val_loss: 0.2846 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2982 - acc: 0.0000e+00 - val_loss: 0.2891 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2970 - acc: 0.0085 - val_loss: 0.2875 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2961 - acc: 0.0000e+00 - val_loss: 0.2865 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2996 - acc: 0.0000e+00 - val_loss: 0.2840 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2982 - acc: 0.0085 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2993 - acc: 0.0000e+00 - val_loss: 0.2911 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3044 - acc: 0.0000e+00 - val_loss: 0.2885 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3000 - acc: 0.0000e+00 - val_loss: 0.2919 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3061 - acc: 0.0000e+00 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3046 - acc: 0.0000e+00 - val_loss: 0.2919 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3020 - acc: 0.0000e+00 - val_loss: 0.2877 - val_acc: 0.0000e+00\n",
      "Epoch 222/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3032 - acc: 0.0085 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3049 - acc: 0.0085 - val_loss: 0.2953 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3069 - acc: 0.0000e+00 - val_loss: 0.2937 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3049 - acc: 0.0000e+00 - val_loss: 0.2882 - val_acc: 0.0256\n",
      "Epoch 226/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3024 - acc: 0.0000e+00 - val_loss: 0.2980 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3062 - acc: 0.0000e+00 - val_loss: 0.2909 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3015 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3015 - acc: 0.0000e+00 - val_loss: 0.2874 - val_acc: 0.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2993 - acc: 0.0000e+00 - val_loss: 0.2810 - val_acc: 0.0000e+00\n",
      "Epoch 231/500\n",
      "117/117 [==============================] - 0s 693us/step - loss: 0.2980 - acc: 0.0000e+00 - val_loss: 0.2852 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "117/117 [==============================] - 0s 845us/step - loss: 0.2988 - acc: 0.0000e+00 - val_loss: 0.2943 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "117/117 [==============================] - 0s 945us/step - loss: 0.3031 - acc: 0.0085 - val_loss: 0.2897 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "117/117 [==============================] - 0s 984us/step - loss: 0.3053 - acc: 0.0000e+00 - val_loss: 0.2911 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.3081 - acc: 0.0000e+0 - ETA: 0s - loss: 0.3034 - acc: 0.0000e+0 - 0s 1ms/step - loss: 0.3013 - acc: 0.0000e+00 - val_loss: 0.2862 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "117/117 [==============================] - 0s 804us/step - loss: 0.3009 - acc: 0.0000e+00 - val_loss: 0.2859 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2981 - acc: 0.0000e+00 - val_loss: 0.2873 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "117/117 [==============================] - 0s 863us/step - loss: 0.2982 - acc: 0.0085 - val_loss: 0.2912 - val_acc: 0.0000e+00\n",
      "Epoch 239/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3047 - acc: 0.0000e+00 - val_loss: 0.2916 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "117/117 [==============================] - 0s 786us/step - loss: 0.3064 - acc: 0.0000e+00 - val_loss: 0.2975 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n",
      "117/117 [==============================] - 0s 909us/step - loss: 0.3071 - acc: 0.0000e+00 - val_loss: 0.2915 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3071 - acc: 0.0000e+00 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "117/117 [==============================] - 0s 761us/step - loss: 0.3052 - acc: 0.0000e+00 - val_loss: 0.2932 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "117/117 [==============================] - 0s 954us/step - loss: 0.3057 - acc: 0.0000e+00 - val_loss: 0.3007 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3071 - acc: 0.0085 - val_loss: 0.2938 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3080 - acc: 0.0000e+00 - val_loss: 0.2988 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3077 - acc: 0.0085 - val_loss: 0.2973 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3098 - acc: 0.0000e+00 - val_loss: 0.2961 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "117/117 [==============================] - 0s 643us/step - loss: 0.3084 - acc: 0.0000e+00 - val_loss: 0.2972 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "117/117 [==============================] - 0s 927us/step - loss: 0.3070 - acc: 0.0000e+00 - val_loss: 0.2978 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3112 - acc: 0.0000e+00 - val_loss: 0.2911 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3113 - acc: 0.0000e+00 - val_loss: 0.2924 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3075 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3070 - acc: 0.0000e+00 - val_loss: 0.3000 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3056 - acc: 0.0000e+00 - val_loss: 0.2955 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3042 - acc: 0.0085 - val_loss: 0.2893 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3033 - acc: 0.0171 - val_loss: 0.2880 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "117/117 [==============================] - 0s 670us/step - loss: 0.3000 - acc: 0.0000e+00 - val_loss: 0.2922 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "117/117 [==============================] - 0s 759us/step - loss: 0.3040 - acc: 0.0085 - val_loss: 0.2909 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "117/117 [==============================] - 0s 843us/step - loss: 0.3020 - acc: 0.0000e+00 - val_loss: 0.2867 - val_acc: 0.0000e+00\n",
      "Epoch 261/500\n",
      "117/117 [==============================] - 0s 760us/step - loss: 0.2986 - acc: 0.0085 - val_loss: 0.2883 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "117/117 [==============================] - 0s 910us/step - loss: 0.2965 - acc: 0.0000e+00 - val_loss: 0.2858 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "117/117 [==============================] - 0s 870us/step - loss: 0.2939 - acc: 0.0000e+00 - val_loss: 0.2807 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2941 - acc: 0.0000e+00 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2987 - acc: 0.0000e+00 - val_loss: 0.2939 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "117/117 [==============================] - 0s 873us/step - loss: 0.3042 - acc: 0.0000e+00 - val_loss: 0.2887 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3037 - acc: 0.0000e+00 - val_loss: 0.2892 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3016 - acc: 0.0000e+00 - val_loss: 0.2947 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3031 - acc: 0.0000e+00 - val_loss: 0.2881 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3008 - acc: 0.0000e+00 - val_loss: 0.2883 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2987 - acc: 0.0000e+00 - val_loss: 0.2897 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2992 - acc: 0.0085 - val_loss: 0.2866 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2994 - acc: 0.0000e+00 - val_loss: 0.2846 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2975 - acc: 0.0000e+00 - val_loss: 0.2842 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2979 - acc: 0.0000e+00 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3014 - acc: 0.0000e+00 - val_loss: 0.2934 - val_acc: 0.0256\n",
      "Epoch 277/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3037 - acc: 0.0085 - val_loss: 0.2826 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "117/117 [==============================] - 0s 934us/step - loss: 0.3017 - acc: 0.0000e+00 - val_loss: 0.2929 - val_acc: 0.0256\n",
      "Epoch 279/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3070 - acc: 0.0085 - val_loss: 0.2964 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3066 - acc: 0.0000e+00 - val_loss: 0.2915 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3078 - acc: 0.0000e+00 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3085 - acc: 0.0085 - val_loss: 0.2972 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3119 - acc: 0.0000e+00 - val_loss: 0.2950 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3110 - acc: 0.0000e+00 - val_loss: 0.3043 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3095 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3111 - acc: 0.0000e+00 - val_loss: 0.3001 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3115 - acc: 0.0000e+00 - val_loss: 0.2985 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "117/117 [==============================] - 0s 806us/step - loss: 0.3088 - acc: 0.0000e+00 - val_loss: 0.2949 - val_acc: 0.0000e+00\n",
      "Epoch 289/500\n",
      "117/117 [==============================] - 0s 934us/step - loss: 0.3063 - acc: 0.0000e+00 - val_loss: 0.2938 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3050 - acc: 0.0000e+00 - val_loss: 0.2943 - val_acc: 0.0000e+00\n",
      "Epoch 291/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3075 - acc: 0.0000e+00 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3071 - acc: 0.0000e+00 - val_loss: 0.2919 - val_acc: 0.0000e+00\n",
      "Epoch 293/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3046 - acc: 0.0000e+00 - val_loss: 0.2841 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2993 - acc: 0.0000e+00 - val_loss: 0.2925 - val_acc: 0.0000e+00\n",
      "Epoch 295/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3042 - acc: 0.0085 - val_loss: 0.2875 - val_acc: 0.0000e+00\n",
      "Epoch 296/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3047 - acc: 0.0000e+00 - val_loss: 0.2978 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "117/117 [==============================] - 0s 760us/step - loss: 0.3066 - acc: 0.0000e+00 - val_loss: 0.2992 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "117/117 [==============================] - 0s 957us/step - loss: 0.3088 - acc: 0.0085 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.0000e+00 - val_loss: 0.2889 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3039 - acc: 0.0000e+00 - val_loss: 0.2855 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3014 - acc: 0.0000e+00 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 302/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3059 - acc: 0.0000e+00 - val_loss: 0.2902 - val_acc: 0.0000e+00\n",
      "Epoch 303/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3031 - acc: 0.0000e+00 - val_loss: 0.2924 - val_acc: 0.0000e+00\n",
      "Epoch 304/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3050 - acc: 0.0000e+00 - val_loss: 0.2963 - val_acc: 0.0000e+00\n",
      "Epoch 305/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3095 - acc: 0.0000e+00 - val_loss: 0.2983 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3085 - acc: 0.0171 - val_loss: 0.2954 - val_acc: 0.0000e+00\n",
      "Epoch 307/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3044 - acc: 0.0000e+00 - val_loss: 0.2889 - val_acc: 0.0000e+00\n",
      "Epoch 308/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3052 - acc: 0.0000e+00 - val_loss: 0.2855 - val_acc: 0.0000e+00\n",
      "Epoch 309/500\n",
      "117/117 [==============================] - 0s 697us/step - loss: 0.3017 - acc: 0.0171 - val_loss: 0.2851 - val_acc: 0.0000e+00\n",
      "Epoch 310/500\n",
      "117/117 [==============================] - 0s 738us/step - loss: 0.3031 - acc: 0.0000e+00 - val_loss: 0.2912 - val_acc: 0.0000e+00\n",
      "Epoch 311/500\n",
      "117/117 [==============================] - 0s 807us/step - loss: 0.3026 - acc: 0.0085 - val_loss: 0.2960 - val_acc: 0.0000e+00\n",
      "Epoch 312/500\n",
      "117/117 [==============================] - 0s 775us/step - loss: 0.3076 - acc: 0.0000e+00 - val_loss: 0.2918 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "117/117 [==============================] - 0s 841us/step - loss: 0.3042 - acc: 0.0000e+00 - val_loss: 0.2858 - val_acc: 0.0000e+00\n",
      "Epoch 314/500\n",
      "117/117 [==============================] - 0s 767us/step - loss: 0.3032 - acc: 0.0000e+00 - val_loss: 0.2856 - val_acc: 0.0000e+00\n",
      "Epoch 315/500\n",
      "117/117 [==============================] - 0s 871us/step - loss: 0.2995 - acc: 0.0000e+00 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "117/117 [==============================] - 0s 793us/step - loss: 0.3026 - acc: 0.0000e+00 - val_loss: 0.2931 - val_acc: 0.0000e+00\n",
      "Epoch 317/500\n",
      "117/117 [==============================] - 0s 837us/step - loss: 0.3085 - acc: 0.0000e+00 - val_loss: 0.2902 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3084 - acc: 0.0000e+00 - val_loss: 0.2908 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "117/117 [==============================] - 0s 806us/step - loss: 0.3017 - acc: 0.0000e+00 - val_loss: 0.2904 - val_acc: 0.0256\n",
      "Epoch 320/500\n",
      "117/117 [==============================] - 0s 802us/step - loss: 0.2998 - acc: 0.0000e+00 - val_loss: 0.2853 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "117/117 [==============================] - 0s 809us/step - loss: 0.2969 - acc: 0.0085 - val_loss: 0.2879 - val_acc: 0.0000e+00\n",
      "Epoch 322/500\n",
      "117/117 [==============================] - 0s 845us/step - loss: 0.2996 - acc: 0.0000e+00 - val_loss: 0.2844 - val_acc: 0.0000e+00\n",
      "Epoch 323/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2962 - acc: 0.0085 - val_loss: 0.2889 - val_acc: 0.0000e+00\n",
      "Epoch 324/500\n",
      "117/117 [==============================] - 0s 654us/step - loss: 0.2989 - acc: 0.0000e+00 - val_loss: 0.2903 - val_acc: 0.0000e+00\n",
      "Epoch 325/500\n",
      "117/117 [==============================] - 0s 751us/step - loss: 0.3025 - acc: 0.0000e+00 - val_loss: 0.2930 - val_acc: 0.0000e+00\n",
      "Epoch 326/500\n",
      "117/117 [==============================] - 0s 853us/step - loss: 0.3019 - acc: 0.0000e+00 - val_loss: 0.2947 - val_acc: 0.0000e+00\n",
      "Epoch 327/500\n",
      "117/117 [==============================] - 0s 802us/step - loss: 0.3017 - acc: 0.0000e+00 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 328/500\n",
      "117/117 [==============================] - 0s 857us/step - loss: 0.2995 - acc: 0.0000e+00 - val_loss: 0.2943 - val_acc: 0.0000e+00\n",
      "Epoch 329/500\n",
      "117/117 [==============================] - 0s 772us/step - loss: 0.3032 - acc: 0.0000e+00 - val_loss: 0.2911 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "117/117 [==============================] - 0s 871us/step - loss: 0.3047 - acc: 0.0000e+00 - val_loss: 0.2889 - val_acc: 0.0000e+00\n",
      "Epoch 331/500\n",
      "117/117 [==============================] - 0s 906us/step - loss: 0.3007 - acc: 0.0000e+00 - val_loss: 0.2895 - val_acc: 0.0000e+00\n",
      "Epoch 332/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2997 - acc: 0.0000e+00 - val_loss: 0.2898 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "117/117 [==============================] - 0s 710us/step - loss: 0.3007 - acc: 0.0000e+00 - val_loss: 0.2859 - val_acc: 0.0000e+00\n",
      "Epoch 334/500\n",
      "117/117 [==============================] - 0s 783us/step - loss: 0.2984 - acc: 0.0000e+00 - val_loss: 0.2849 - val_acc: 0.0000e+00\n",
      "Epoch 335/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3003 - acc: 0.0085 - val_loss: 0.2919 - val_acc: 0.0256\n",
      "Epoch 336/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3038 - acc: 0.0000e+00 - val_loss: 0.2924 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3045 - acc: 0.0085 - val_loss: 0.2894 - val_acc: 0.0000e+00\n",
      "Epoch 338/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2979 - acc: 0.0000e+00 - val_loss: 0.2806 - val_acc: 0.0000e+00\n",
      "Epoch 339/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2908 - acc: 0.0000e+00 - val_loss: 0.2791 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "117/117 [==============================] - 0s 819us/step - loss: 0.2923 - acc: 0.0000e+00 - val_loss: 0.2816 - val_acc: 0.0000e+00\n",
      "Epoch 341/500\n",
      "117/117 [==============================] - 0s 784us/step - loss: 0.2931 - acc: 0.0000e+00 - val_loss: 0.2880 - val_acc: 0.0000e+00\n",
      "Epoch 342/500\n",
      "117/117 [==============================] - 0s 734us/step - loss: 0.2979 - acc: 0.0171 - val_loss: 0.2869 - val_acc: 0.0000e+00\n",
      "Epoch 343/500\n",
      "117/117 [==============================] - 0s 696us/step - loss: 0.2971 - acc: 0.0000e+00 - val_loss: 0.2929 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3021 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 345/500\n",
      "117/117 [==============================] - 0s 944us/step - loss: 0.3005 - acc: 0.0085 - val_loss: 0.2893 - val_acc: 0.0000e+00\n",
      "Epoch 346/500\n",
      "117/117 [==============================] - 0s 836us/step - loss: 0.3039 - acc: 0.0000e+00 - val_loss: 0.2906 - val_acc: 0.0000e+00\n",
      "Epoch 347/500\n",
      "117/117 [==============================] - 0s 919us/step - loss: 0.3024 - acc: 0.0000e+00 - val_loss: 0.2918 - val_acc: 0.0000e+00\n",
      "Epoch 348/500\n",
      "117/117 [==============================] - 0s 847us/step - loss: 0.3038 - acc: 0.0085 - val_loss: 0.2928 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "117/117 [==============================] - 0s 967us/step - loss: 0.3075 - acc: 0.0000e+00 - val_loss: 0.2984 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "117/117 [==============================] - 0s 931us/step - loss: 0.3122 - acc: 0.0000e+00 - val_loss: 0.2921 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3096 - acc: 0.0000e+00 - val_loss: 0.2961 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "117/117 [==============================] - 0s 754us/step - loss: 0.3036 - acc: 0.0000e+00 - val_loss: 0.2932 - val_acc: 0.0000e+00\n",
      "Epoch 353/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3035 - acc: 0.0000e+00 - val_loss: 0.2828 - val_acc: 0.0000e+00\n",
      "Epoch 354/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2983 - acc: 0.0000e+00 - val_loss: 0.2857 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2945 - acc: 0.0000e+00 - val_loss: 0.2854 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2990 - acc: 0.0000e+00 - val_loss: 0.2829 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2992 - acc: 0.0085 - val_loss: 0.2888 - val_acc: 0.0256\n",
      "Epoch 358/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3035 - acc: 0.0000e+00 - val_loss: 0.2858 - val_acc: 0.0000e+00\n",
      "Epoch 359/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2987 - acc: 0.0000e+00 - val_loss: 0.2916 - val_acc: 0.0000e+00\n",
      "Epoch 360/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3005 - acc: 0.0000e+00 - val_loss: 0.2857 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3014 - acc: 0.0000e+00 - val_loss: 0.2906 - val_acc: 0.0000e+00\n",
      "Epoch 362/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3041 - acc: 0.0000e+00 - val_loss: 0.2976 - val_acc: 0.0000e+00\n",
      "Epoch 363/500\n",
      "117/117 [==============================] - 0s 702us/step - loss: 0.3063 - acc: 0.0000e+00 - val_loss: 0.2933 - val_acc: 0.0000e+00\n",
      "Epoch 364/500\n",
      "117/117 [==============================] - 0s 732us/step - loss: 0.3064 - acc: 0.0000e+00 - val_loss: 0.2896 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n",
      "117/117 [==============================] - 0s 901us/step - loss: 0.3055 - acc: 0.0000e+00 - val_loss: 0.2911 - val_acc: 0.0000e+00\n",
      "Epoch 366/500\n",
      "117/117 [==============================] - 0s 875us/step - loss: 0.3065 - acc: 0.0000e+00 - val_loss: 0.2946 - val_acc: 0.0256\n",
      "Epoch 367/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3055 - acc: 0.0000e+00 - val_loss: 0.2944 - val_acc: 0.0000e+00\n",
      "Epoch 368/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3045 - acc: 0.0000e+00 - val_loss: 0.2877 - val_acc: 0.0256\n",
      "Epoch 369/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3008 - acc: 0.0000e+00 - val_loss: 0.2854 - val_acc: 0.0000e+00\n",
      "Epoch 370/500\n",
      "117/117 [==============================] - 0s 733us/step - loss: 0.3015 - acc: 0.0000e+00 - val_loss: 0.2884 - val_acc: 0.0000e+00\n",
      "Epoch 371/500\n",
      "117/117 [==============================] - 0s 777us/step - loss: 0.3024 - acc: 0.0000e+00 - val_loss: 0.2878 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "117/117 [==============================] - 0s 931us/step - loss: 0.2990 - acc: 0.0085 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 373/500\n",
      "117/117 [==============================] - 0s 867us/step - loss: 0.3027 - acc: 0.0085 - val_loss: 0.2950 - val_acc: 0.0000e+00\n",
      "Epoch 374/500\n",
      "117/117 [==============================] - 0s 791us/step - loss: 0.3043 - acc: 0.0000e+00 - val_loss: 0.2959 - val_acc: 0.0000e+00\n",
      "Epoch 375/500\n",
      "117/117 [==============================] - 0s 859us/step - loss: 0.3044 - acc: 0.0171 - val_loss: 0.2930 - val_acc: 0.0000e+00\n",
      "Epoch 376/500\n",
      "117/117 [==============================] - 0s 742us/step - loss: 0.3021 - acc: 0.0000e+00 - val_loss: 0.2935 - val_acc: 0.0000e+00\n",
      "Epoch 377/500\n",
      "117/117 [==============================] - 0s 922us/step - loss: 0.3034 - acc: 0.0000e+00 - val_loss: 0.2893 - val_acc: 0.0000e+00\n",
      "Epoch 378/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.0085 - val_loss: 0.2926 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.0000e+00 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
      "Epoch 380/500\n",
      "117/117 [==============================] - 0s 750us/step - loss: 0.3038 - acc: 0.0000e+00 - val_loss: 0.2890 - val_acc: 0.0000e+00\n",
      "Epoch 381/500\n",
      "117/117 [==============================] - 0s 867us/step - loss: 0.3007 - acc: 0.0000e+00 - val_loss: 0.2901 - val_acc: 0.0000e+00\n",
      "Epoch 382/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3013 - acc: 0.0000e+00 - val_loss: 0.2942 - val_acc: 0.0000e+00\n",
      "Epoch 383/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3043 - acc: 0.0000e+00 - val_loss: 0.2912 - val_acc: 0.0256\n",
      "Epoch 384/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3065 - acc: 0.0000e+00 - val_loss: 0.2964 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3068 - acc: 0.0085 - val_loss: 0.2929 - val_acc: 0.0000e+00\n",
      "Epoch 386/500\n",
      "117/117 [==============================] - 0s 956us/step - loss: 0.3056 - acc: 0.0000e+00 - val_loss: 0.2961 - val_acc: 0.0000e+00\n",
      "Epoch 387/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3079 - acc: 0.0000e+00 - val_loss: 0.2927 - val_acc: 0.0000e+00\n",
      "Epoch 388/500\n",
      "117/117 [==============================] - 0s 779us/step - loss: 0.3082 - acc: 0.0000e+00 - val_loss: 0.2938 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3055 - acc: 0.0000e+00 - val_loss: 0.2942 - val_acc: 0.0000e+00\n",
      "Epoch 390/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3033 - acc: 0.0000e+00 - val_loss: 0.2956 - val_acc: 0.0000e+00\n",
      "Epoch 391/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.0000e+00 - val_loss: 0.2880 - val_acc: 0.0000e+00\n",
      "Epoch 392/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2998 - acc: 0.0000e+00 - val_loss: 0.2861 - val_acc: 0.0000e+00\n",
      "Epoch 393/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2981 - acc: 0.0000e+00 - val_loss: 0.2881 - val_acc: 0.0000e+00\n",
      "Epoch 394/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.0000e+00 - val_loss: 0.2947 - val_acc: 0.0000e+00\n",
      "Epoch 395/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3042 - acc: 0.0000e+00 - val_loss: 0.2938 - val_acc: 0.0000e+00\n",
      "Epoch 396/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3063 - acc: 0.0000e+00 - val_loss: 0.2940 - val_acc: 0.0000e+00\n",
      "Epoch 397/500\n",
      "117/117 [==============================] - 0s 773us/step - loss: 0.3035 - acc: 0.0000e+00 - val_loss: 0.2921 - val_acc: 0.0000e+00\n",
      "Epoch 398/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3060 - acc: 0.0000e+00 - val_loss: 0.2936 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3057 - acc: 0.0000e+00 - val_loss: 0.2878 - val_acc: 0.0000e+00\n",
      "Epoch 400/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3033 - acc: 0.0171 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3020 - acc: 0.0000e+00 - val_loss: 0.2955 - val_acc: 0.0000e+00\n",
      "Epoch 402/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3046 - acc: 0.0171 - val_loss: 0.2856 - val_acc: 0.0000e+00\n",
      "Epoch 403/500\n",
      "117/117 [==============================] - 0s 975us/step - loss: 0.2967 - acc: 0.0000e+00 - val_loss: 0.2866 - val_acc: 0.0000e+00\n",
      "Epoch 404/500\n",
      "117/117 [==============================] - 0s 907us/step - loss: 0.2993 - acc: 0.0085 - val_loss: 0.2877 - val_acc: 0.0000e+00\n",
      "Epoch 405/500\n",
      "117/117 [==============================] - 0s 805us/step - loss: 0.2986 - acc: 0.0085 - val_loss: 0.2860 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "117/117 [==============================] - 0s 921us/step - loss: 0.2940 - acc: 0.0000e+00 - val_loss: 0.2868 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.2948 - acc: 0.0000e+00 - val_loss: 0.2856 - val_acc: 0.0000e+00\n",
      "Epoch 408/500\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.3014 - acc: 0.0000e+0 - 0s 782us/step - loss: 0.2953 - acc: 0.0000e+00 - val_loss: 0.2867 - val_acc: 0.0000e+00\n",
      "Epoch 409/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3021 - acc: 0.0000e+00 - val_loss: 0.2851 - val_acc: 0.0000e+00\n",
      "Epoch 410/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3005 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 411/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3038 - acc: 0.0000e+00 - val_loss: 0.2950 - val_acc: 0.0000e+00\n",
      "Epoch 412/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3068 - acc: 0.0000e+00 - val_loss: 0.2903 - val_acc: 0.0000e+00\n",
      "Epoch 413/500\n",
      "117/117 [==============================] - 0s 680us/step - loss: 0.3057 - acc: 0.0000e+00 - val_loss: 0.2903 - val_acc: 0.0000e+00\n",
      "Epoch 414/500\n",
      "117/117 [==============================] - 0s 807us/step - loss: 0.3026 - acc: 0.0000e+00 - val_loss: 0.2974 - val_acc: 0.0000e+00\n",
      "Epoch 415/500\n",
      "117/117 [==============================] - 0s 981us/step - loss: 0.3030 - acc: 0.0000e+00 - val_loss: 0.3009 - val_acc: 0.0000e+00\n",
      "Epoch 416/500\n",
      "117/117 [==============================] - 0s 874us/step - loss: 0.3080 - acc: 0.0085 - val_loss: 0.2930 - val_acc: 0.0000e+00\n",
      "Epoch 417/500\n",
      "117/117 [==============================] - 0s 839us/step - loss: 0.3102 - acc: 0.0000e+00 - val_loss: 0.2938 - val_acc: 0.0000e+00\n",
      "Epoch 418/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3070 - acc: 0.0000e+00 - val_loss: 0.2911 - val_acc: 0.0000e+00\n",
      "Epoch 419/500\n",
      "117/117 [==============================] - 0s 770us/step - loss: 0.3031 - acc: 0.0000e+00 - val_loss: 0.2903 - val_acc: 0.0000e+00\n",
      "Epoch 420/500\n",
      "117/117 [==============================] - 0s 742us/step - loss: 0.3057 - acc: 0.0000e+00 - val_loss: 0.2906 - val_acc: 0.0000e+00\n",
      "Epoch 421/500\n",
      "117/117 [==============================] - 0s 872us/step - loss: 0.3046 - acc: 0.0171 - val_loss: 0.2936 - val_acc: 0.0000e+00\n",
      "Epoch 422/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3049 - acc: 0.0000e+00 - val_loss: 0.2847 - val_acc: 0.0000e+00\n",
      "Epoch 423/500\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2990 - acc: 0.0000e+00 - val_loss: 0.2917 - val_acc: 0.0000e+00\n",
      "Epoch 424/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3064 - acc: 0.0000e+00 - val_loss: 0.2930 - val_acc: 0.0000e+00\n",
      "Epoch 425/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3074 - acc: 0.0000e+00 - val_loss: 0.3001 - val_acc: 0.0256\n",
      "Epoch 426/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3088 - acc: 0.0000e+00 - val_loss: 0.2965 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3060 - acc: 0.0000e+00 - val_loss: 0.2955 - val_acc: 0.0000e+00\n",
      "Epoch 428/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3068 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 429/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3047 - acc: 0.0000e+00 - val_loss: 0.2957 - val_acc: 0.0000e+00\n",
      "Epoch 430/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3060 - acc: 0.0000e+00 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 431/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3034 - acc: 0.0000e+00 - val_loss: 0.2898 - val_acc: 0.0000e+00\n",
      "Epoch 432/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3016 - acc: 0.0000e+00 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 433/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2993 - acc: 0.0000e+00 - val_loss: 0.2957 - val_acc: 0.0000e+00\n",
      "Epoch 434/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3040 - acc: 0.0000e+00 - val_loss: 0.2904 - val_acc: 0.0000e+00\n",
      "Epoch 435/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3011 - acc: 0.0000e+00 - val_loss: 0.2895 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3046 - acc: 0.0000e+00 - val_loss: 0.2915 - val_acc: 0.0000e+00\n",
      "Epoch 437/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3032 - acc: 0.0000e+00 - val_loss: 0.2915 - val_acc: 0.0000e+00\n",
      "Epoch 438/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3005 - acc: 0.0000e+00 - val_loss: 0.2947 - val_acc: 0.0000e+00\n",
      "Epoch 439/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3031 - acc: 0.0000e+00 - val_loss: 0.2942 - val_acc: 0.0000e+00\n",
      "Epoch 440/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3032 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 441/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3081 - acc: 0.0000e+00 - val_loss: 0.2989 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3104 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 443/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3067 - acc: 0.0000e+00 - val_loss: 0.2919 - val_acc: 0.0000e+00\n",
      "Epoch 444/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.0000e+00 - val_loss: 0.2991 - val_acc: 0.0256\n",
      "Epoch 445/500\n",
      "117/117 [==============================] - 0s 951us/step - loss: 0.3101 - acc: 0.0000e+00 - val_loss: 0.2929 - val_acc: 0.0000e+00\n",
      "Epoch 446/500\n",
      "117/117 [==============================] - 0s 656us/step - loss: 0.3059 - acc: 0.0000e+00 - val_loss: 0.2946 - val_acc: 0.0000e+00\n",
      "Epoch 447/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3027 - acc: 0.0000e+00 - val_loss: 0.2904 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3020 - acc: 0.0000e+00 - val_loss: 0.2895 - val_acc: 0.0000e+00\n",
      "Epoch 449/500\n",
      "117/117 [==============================] - 0s 957us/step - loss: 0.3035 - acc: 0.0000e+00 - val_loss: 0.2907 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3008 - acc: 0.0085 - val_loss: 0.2876 - val_acc: 0.0000e+00\n",
      "Epoch 451/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3013 - acc: 0.0000e+00 - val_loss: 0.2892 - val_acc: 0.0000e+00\n",
      "Epoch 452/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3009 - acc: 0.0085 - val_loss: 0.2918 - val_acc: 0.0000e+00\n",
      "Epoch 453/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3024 - acc: 0.0000e+00 - val_loss: 0.2868 - val_acc: 0.0000e+00\n",
      "Epoch 454/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2998 - acc: 0.0000e+00 - val_loss: 0.2862 - val_acc: 0.0000e+00\n",
      "Epoch 455/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2973 - acc: 0.0000e+00 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "117/117 [==============================] - 0s 675us/step - loss: 0.2990 - acc: 0.0000e+00 - val_loss: 0.2941 - val_acc: 0.0000e+00\n",
      "Epoch 457/500\n",
      "117/117 [==============================] - 0s 900us/step - loss: 0.3029 - acc: 0.0000e+00 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 986us/step - loss: 0.3049 - acc: 0.0000e+00 - val_loss: 0.2916 - val_acc: 0.0000e+00\n",
      "Epoch 459/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3058 - acc: 0.0000e+00 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 460/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3017 - acc: 0.0000e+00 - val_loss: 0.2909 - val_acc: 0.0000e+00\n",
      "Epoch 461/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3009 - acc: 0.0000e+00 - val_loss: 0.2857 - val_acc: 0.0000e+00\n",
      "Epoch 462/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2998 - acc: 0.0000e+00 - val_loss: 0.2814 - val_acc: 0.0000e+00\n",
      "Epoch 463/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2969 - acc: 0.0000e+00 - val_loss: 0.2849 - val_acc: 0.0000e+00\n",
      "Epoch 464/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2983 - acc: 0.0000e+00 - val_loss: 0.2947 - val_acc: 0.0513\n",
      "Epoch 465/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3035 - acc: 0.0171 - val_loss: 0.2924 - val_acc: 0.0000e+00\n",
      "Epoch 466/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3045 - acc: 0.0000e+00 - val_loss: 0.2879 - val_acc: 0.0000e+00\n",
      "Epoch 467/500\n",
      "117/117 [==============================] - 0s 900us/step - loss: 0.3061 - acc: 0.0000e+00 - val_loss: 0.2940 - val_acc: 0.0000e+00\n",
      "Epoch 468/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3059 - acc: 0.0085 - val_loss: 0.2938 - val_acc: 0.0000e+00\n",
      "Epoch 469/500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3062 - acc: 0.0000e+00 - val_loss: 0.2967 - val_acc: 0.0000e+00\n",
      "Epoch 470/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3047 - acc: 0.0085 - val_loss: 0.2932 - val_acc: 0.0000e+00\n",
      "Epoch 471/500\n",
      "117/117 [==============================] - 0s 811us/step - loss: 0.3021 - acc: 0.0000e+00 - val_loss: 0.2875 - val_acc: 0.0000e+00\n",
      "Epoch 472/500\n",
      "117/117 [==============================] - 0s 910us/step - loss: 0.3021 - acc: 0.0000e+00 - val_loss: 0.2877 - val_acc: 0.0000e+00\n",
      "Epoch 473/500\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3006 - acc: 0.0000e+00 - val_loss: 0.2883 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2977 - acc: 0.0000e+00 - val_loss: 0.2890 - val_acc: 0.0000e+00\n",
      "Epoch 475/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3012 - acc: 0.0000e+00 - val_loss: 0.2882 - val_acc: 0.0000e+00\n",
      "Epoch 476/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3032 - acc: 0.0000e+00 - val_loss: 0.2871 - val_acc: 0.0000e+00\n",
      "Epoch 477/500\n",
      "117/117 [==============================] - 0s 916us/step - loss: 0.3013 - acc: 0.0000e+00 - val_loss: 0.2871 - val_acc: 0.0000e+00\n",
      "Epoch 478/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3005 - acc: 0.0000e+00 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "117/117 [==============================] - 0s 667us/step - loss: 0.3010 - acc: 0.0000e+00 - val_loss: 0.2877 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3032 - acc: 0.0000e+00 - val_loss: 0.2897 - val_acc: 0.0000e+00\n",
      "Epoch 481/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3041 - acc: 0.0000e+00 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 482/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3022 - acc: 0.0000e+00 - val_loss: 0.2891 - val_acc: 0.0000e+00\n",
      "Epoch 483/500\n",
      "117/117 [==============================] - 0s 936us/step - loss: 0.3030 - acc: 0.0000e+00 - val_loss: 0.2876 - val_acc: 0.0000e+00\n",
      "Epoch 484/500\n",
      "117/117 [==============================] - 0s 889us/step - loss: 0.3040 - acc: 0.0000e+00 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 485/500\n",
      "117/117 [==============================] - 0s 838us/step - loss: 0.3058 - acc: 0.0000e+00 - val_loss: 0.2978 - val_acc: 0.0000e+00\n",
      "Epoch 486/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3071 - acc: 0.0085 - val_loss: 0.2905 - val_acc: 0.0000e+00\n",
      "Epoch 487/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3052 - acc: 0.0000e+00 - val_loss: 0.2932 - val_acc: 0.0000e+00\n",
      "Epoch 488/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3045 - acc: 0.0000e+00 - val_loss: 0.2934 - val_acc: 0.0000e+00\n",
      "Epoch 489/500\n",
      "117/117 [==============================] - 0s 970us/step - loss: 0.3049 - acc: 0.0000e+00 - val_loss: 0.2901 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "117/117 [==============================] - 0s 867us/step - loss: 0.3019 - acc: 0.0000e+00 - val_loss: 0.2897 - val_acc: 0.0000e+00\n",
      "Epoch 491/500\n",
      "117/117 [==============================] - 0s 818us/step - loss: 0.3042 - acc: 0.0000e+00 - val_loss: 0.2881 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3002 - acc: 0.0000e+00 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 493/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3009 - acc: 0.0000e+00 - val_loss: 0.2891 - val_acc: 0.0000e+00\n",
      "Epoch 494/500\n",
      "117/117 [==============================] - 0s 844us/step - loss: 0.3016 - acc: 0.0085 - val_loss: 0.2891 - val_acc: 0.0000e+00\n",
      "Epoch 495/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2997 - acc: 0.0000e+00 - val_loss: 0.2869 - val_acc: 0.0000e+00\n",
      "Epoch 496/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2995 - acc: 0.0000e+00 - val_loss: 0.2909 - val_acc: 0.0000e+00\n",
      "Epoch 497/500\n",
      "117/117 [==============================] - 0s 916us/step - loss: 0.3046 - acc: 0.0000e+00 - val_loss: 0.2945 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3037 - acc: 0.0000e+00 - val_loss: 0.2903 - val_acc: 0.0000e+00\n",
      "Epoch 499/500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3033 - acc: 0.0000e+00 - val_loss: 0.2901 - val_acc: 0.0000e+00\n",
      "Epoch 500/500\n",
      "117/117 [==============================] - 0s 686us/step - loss: 0.3019 - acc: 0.0000e+00 - val_loss: 0.2886 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "nb_epoch = 500\n",
    "batch_size = 30\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard]).history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Evaluation\n",
    "the current paraments works very promising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d6e90b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder = load_model('model.h5')\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');\n",
    "\n",
    "predictions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.201862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.201519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.201688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.201878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.201988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.202279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error\n",
       "count             39.000000\n",
       "mean               0.201862\n",
       "std                0.000203\n",
       "min                0.201519\n",
       "25%                0.201688\n",
       "50%                0.201878\n",
       "75%                0.201988\n",
       "max                0.202279"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = pd.DataFrame({'reconstruction_error': mse})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay  according to the result, we concurrently set the threshold as 0.2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-78a849e74bba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mthes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.201988\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "l = len(X_test)\n",
    "thes = 0.201988\n",
    "for i in range(l):\n",
    "    error = np.mean(np.power(X_test[i] - predictions[i], 2))     \n",
    "    plt.plot(X_test[i])\n",
    "    if(error>thes):\n",
    "        plt.title('unaccepted product') #subplot 211 title\n",
    "    else:\n",
    "        plt.title('accepted product') #subplot 211 title\n",
    "    plt.ylim((0.65,0.74))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
